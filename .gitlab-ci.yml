# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  DEPLOY_VARIABLE: "nightly"
  MINICONDA_VERSION: "latest"

stages:
- build
- test
- deploy
- Trigger-cross-projects

build:linux:
  stage: build
  tags:
    - linux
  image: continuumio/miniconda3:latest
  before_script:
    - apt update -yq && apt -yq install build-essential doxygen   
  script:
    - echo "I am the build stage."
    - source activate base
    # Create documentation.i for python
    - | 
      cd doc && doxygen
      cd ../build_tools
      python doxy2swig.py ../doc/_build/xml/index.xml ../ext/python/documentation.i && cd ..
    - conda install mamba boa conda-verify -c conda-forge    
    # Take care that linked against same libraries as IMP
    - mamba install imp -c salilab
    - if [[ python -c "import IMP;print(IMP.__version__ < '2.15.0')" == "True" ]]; then mv meta_imp_2.14.yaml meta.yaml; fi      
    # Build the recipe
    - conda config --add channels salilab
    - conda mambabuild conda-recipe --output-folder bld-dir
  artifacts:
    expire_in: 7 days
    paths:
      - bld-dir/

test:linux:
  variables:
    MINICONDA_OS: "Linux"
  stage: test
  tags:
    - linux
  image: ubuntu:latest
  before_script:
    - export DEBIAN_FRONTEND=noninteractive
    - apt update -yq
    - apt install -yq procps wget git git-lfs
    # Download and install miniconda
    - wget https://repo.continuum.io/miniconda/Miniconda3-$MINICONDA_VERSION-$MINICONDA_OS-x86_64.sh -O miniconda.sh
    - bash miniconda.sh -b -p $HOME/miniconda
    - export PATH="$HOME/miniconda/bin:$PATH"
    # setup conda to always accept commands
    - conda config --set always_yes yes --set changeps1 no
  script:
    - echo "I am a test stage job for debian, running on docker"
    - source activate base
    - conda install mamba conda-verify -c conda-forge
    - mamba update -y -n base -c defaults --all
    - |
      conda config --add channels salilab
      conda config --add channels "file://`pwd`/bld-dir"
    - git clone https://gitlab.peulen.xyz/tpeulen/tttr-data --depth 1
    - mamba create -n test python tttrlib nose scipy
    - conda activate test
    - |
      cd test
      nosetests

deploy:
  stage: deploy
  image: continuumio/miniconda3:latest
  tags:
    - linux
  dependencies:
    - build:linux
  script:
    - echo "I am a deploy stage."
    - source activate
    - conda install anaconda-client
    - echo $CI_COMMIT_REF_NAME
    - if [[ "$CI_COMMIT_REF_NAME" == "master" ]]; then DEPLOY_VARIABLE=main; else DEPLOY_VARIABLE=nightly; fi
    - anaconda -t ${ANACONDA_API_TOKEN} upload -l ${DEPLOY_VARIABLE} -u ${CONDA_USER} --force bld-dir/linux-64/*.tar.bz2

# TODO
# doc:
#   stage: deploy
#   image: continuumio/miniconda3:latest
#   tags:
#     - linux
#   dependencies:
#     - build:linux
#   before_script:
#     - apt-get update -qy
#     - apt-get install -y lftp  
#   script:
#     - echo "I am a deploy stage... Building documentation."
#     - source activate base
#     - conda env create -f doc/environment.yml
#     - conda activate doc
#     - | 
#       cd doc
#       doxygen
#       make html
#     - echo "I am a deploy stage... Uploading documentation."
#     - lftp -e "open sftp://192.168.124.254; user $FTP_USERNAME $FTP_PASSWORD; mirror -X .* -X .*/ --reverse --verbose --delete local-folder/ destination-folder/; bye"

# Downstream projects
tttrconvert:
  stage: Trigger-cross-projects
  trigger: tpeulen/tttrconvert

fit2x:
  stage: Trigger-cross-projects
  trigger: tpeulen/fit2x

clsmview:
  stage: Trigger-cross-projects
  trigger: tpeulen/clsmview

scikit-fluorescence:
  stage: Trigger-cross-projects
  trigger: tpeulen/scikit-fluorescence
